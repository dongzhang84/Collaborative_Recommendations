{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-logistics",
   "metadata": {},
   "source": [
    "# Test KNN and SVD algorithms in surprise\n",
    "\n",
    "Follow this link: https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "How to do the test? Not complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "straight-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "b = [2, 4]\n",
    "c = [2.5, 4]\n",
    "d = [4.5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satellite-prisoner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "0.5\n",
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "print(spatial.distance.euclidean(c, a))\n",
    "\n",
    "print(spatial.distance.euclidean(c, b))\n",
    "\n",
    "print(spatial.distance.euclidean(c, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-survival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004504527406047898\n",
      "0.004504527406047898\n",
      "0.015137225946083022\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(spatial.distance.cosine(c,a))\n",
    "\n",
    "print(spatial.distance.cosine(c,b))\n",
    "\n",
    "print(spatial.distance.cosine(c,d))\n",
    "\n",
    "print(spatial.distance.cosine(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-aspect",
   "metadata": {},
   "source": [
    "## Matrix factorization\n",
    "\n",
    "- singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "phantom-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# This is the same data that was plotted for similarity earlier\n",
    "# with one new user \"E\" who has rated only movie 1\n",
    "ratings_dict = {\n",
    "    \"item\": [1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    \"user\": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],\n",
    "    \"rating\": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "harmful-conviction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item user  rating\n",
       "0     1    A     1.0\n",
       "1     2    A     2.0\n",
       "2     1    B     2.0\n",
       "3     2    B     4.0\n",
       "4     1    C     2.5\n",
       "5     2    C     4.0\n",
       "6     1    D     4.5\n",
       "7     2    D     5.0\n",
       "8     1    E     3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "respiratory-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.reader.Reader at 0x7f9d9281d190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gorgeous-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to /Users/dongzhang/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "# Loads Pandas dataframe\n",
    "data = Dataset.load_from_df(df[[\"user\", \"item\", \"rating\"]], reader)\n",
    "# Loads the builtin Movielens-100k data\n",
    "movielens = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "favorite-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7f9d929b1dc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-consciousness",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours (k-NN)\n",
    "\n",
    "- **name** contains the similarity metric to use. Options are cosine, msd, pearson, or pearson_baseline. The default is msd.\n",
    "\n",
    "- **user_based** is a boolean that tells whether the approach will be user-based or item-based. The default is True, which means the user-based approach will be used.\n",
    "\n",
    "- **min_support** is the minimum number of common items needed between users to consider them for similarity. For the item-based approach, this corresponds to the minimum number of common users for two items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atmospheric-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "# To use item-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operational-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assisted-apollo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7f9d92a0d760>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-speech",
   "metadata": {},
   "source": [
    "### Case study: how the user E would rate the movie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "higher-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='E', iid=2, r_ui=None, est=4.15, details={'actual_k': 1, 'was_impossible': False})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = algo.predict('E', 2)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forced-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9433819009719057\n",
      "{'sim_options': {'name': 'msd', 'min_support': 3, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "white-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to do the test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-compound",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "- **n_epochs** is the number of iterations of SGD, which is basically an iterative method used in statistics to minimize a function.\n",
    "\n",
    "- **lr_all** is the learning rate for all parameters, which is a parameter that decides how much the parameters are adjusted in each iteration.\n",
    "\n",
    "- **reg_all** is the regularization term for all parameters, which is a penalty term added to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qualified-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635607198455595\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-florist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
